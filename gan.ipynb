{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://data.mendeley.com/datasets/3t9vbwxgr5/2/files/d2c58546-d8be-4d57-af14-b61337c927b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "from IPython.display import Markdown as md\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pop        7042\n",
       "country    5445\n",
       "blues      4604\n",
       "rock       4034\n",
       "jazz       3845\n",
       "reggae     2498\n",
       "hip hop     904\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"tcc_ceds_music.csv\", index_col=0)\n",
    "df[\"genre\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    like sound hear ghetto music ghetto music ghet...\n",
       "1    start heart take time heart come everybody fea...\n",
       "2    number soundlive ghetto music produce krsone w...\n",
       "3    right right bring smooth alright hello whassup...\n",
       "4    blueprint musty fusty clear noncommercial brin...\n",
       "Name: lyrics, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_df = df[df[\"genre\"] == \"hip hop\"][\"lyrics\"].reset_index(drop=True)\n",
    "# pop_df = df[\"lyrics\"].reset_index(drop=True)\n",
    "pop_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from functools import reduce\n",
    "# vocab_set = set(reduce(lambda x, y: x+y, pop_df.str.split(\" \")))\n",
    "# vocab = sorted(list(vocab_set))\n",
    "# print(len(vocab), pop_df.shape[0])\n",
    "# # vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(904, 11475)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(decode_error='ignore')\n",
    "total_features_words = vectorizer.fit_transform(pop_df)\n",
    "total_features_words.shape\n",
    "# 7042 -> Training instances\n",
    "# 21954 -> Total words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to trim the vocab size. Filter by IDF value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(904, 11451)\n",
      "1.3294253014913568 7.114787763139981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rchaks/opt/anaconda3/envs/aml-proj/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12sheba       7.114788\n",
       "aaaaah        7.114788\n",
       "aaaahiight    7.114788\n",
       "aaaayo        7.114788\n",
       "aaah          7.114788\n",
       "                ...   \n",
       "zoovier       7.114788\n",
       "zoovin        7.114788\n",
       "zrymowaem     7.114788\n",
       "zulu          6.198497\n",
       "zzoe          7.114788\n",
       "Length: 11451, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(decode_error='ignore'\n",
    "                            # ,ngram_range = (1,2)\n",
    "                            ,use_idf = True\n",
    "                            ,strip_accents = 'ascii'\n",
    "                            # ,smooth_idf = False\n",
    "                            )\n",
    "song_vectors = vectorizer.fit_transform(pop_df)\n",
    "print(song_vectors.shape)\n",
    "# 7042 -> Training instances\n",
    "# 21954 -> Total words\n",
    "print(min(vectorizer.idf_), max(vectorizer.idf_))\n",
    "idf_vocab = pd.Series(vectorizer.idf_, index= vectorizer.get_feature_names())\n",
    "idf_vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Word Distribution')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "plt.hist(vectorizer._tfidf.idf_)\n",
    "plt.xlabel(\"IDF Score\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Word Distribution\", fontsize = 20)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1262\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "act       4.917563\n",
       "actin     4.629881\n",
       "action    4.974722\n",
       "admit     5.035346\n",
       "afraid    4.917563\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting top 10% most frequently occouring words\n",
    "idf_vocab = idf_vocab[idf_vocab <= idf_vocab.quantile(q = 0.10)]\n",
    "print(len(idf_vocab))\n",
    "idf_vocab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(904, 11451)\n",
      "['act' 'actin' 'action' ... 'york' 'young' 'zone']\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vectorizer = CountVectorizer(decode_error='ignore'\n",
    "                            # ,ngram_range = (1,2)\n",
    "                            ,strip_accents = 'ascii'\n",
    "                            # ,smooth_idf = False\n",
    "                            ,vocabulary = set(idf_vocab.index)\n",
    "                        )\n",
    "X = vectorizer.fit_transform(pop_df)\n",
    "print(song_vectors.shape)\n",
    "# 7042 -> Training instances\n",
    "# 21954 -> Total words\n",
    "vocab= vectorizer.get_feature_names_out()\n",
    "print(vocab)\n",
    "print(X.toarray()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Logger\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd.variable import Variable\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([904, 1262]) 904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fd212925fd0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor(X.toarray())\n",
    "print(X.shape, X.shape[0])\n",
    "vocab_size = X.shape[1]\n",
    "\n",
    "batch_size = 32\n",
    "num_batches = X.shape[0]//batch_size\n",
    "\n",
    "dataloader = DataLoader(X, batch_size= batch_size)\n",
    "dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminatorNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A three hidden-layer discriminative neural network\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(DiscriminatorNet, self).__init__()\n",
    "        n_features = vocab_size\n",
    "        n_out = 1\n",
    "        \n",
    "        self.hidden0 = nn.Sequential( \n",
    "            nn.Linear(n_features, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.hidden1 = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.hidden2 = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.out = nn.Sequential(\n",
    "            torch.nn.Linear(256, n_out),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.type(torch.FloatTensor)\n",
    "        # print(\"Discriminator\",x.shape)\n",
    "        x = self.hidden0(x)\n",
    "        # print(x.shape)\n",
    "        x = self.hidden1(x)\n",
    "        # print(x.shape)\n",
    "        x = self.hidden2(x)\n",
    "        # print(x.shape)\n",
    "        x = self.out(x)\n",
    "        # print(x.shape)\n",
    "        return x\n",
    "    \n",
    "def vec_to_text(array):\n",
    "    return list(map(lambda vec: \" \".join(list(vocab[vec > 0.5])), array))\n",
    "\n",
    "def text_to_vec(array):\n",
    "    return vectorizer.fit_transform(array)\n",
    "    # return images.view(images.size(0), 784)\n",
    "\n",
    "# def vectors_to_images(vectors):\n",
    "#     return vectors.view(vectors.size(0), 1, 28, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator Netowrk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A three hidden-layer generative neural network\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(GeneratorNet, self).__init__()\n",
    "        n_features = 1000\n",
    "        n_out = vocab_size\n",
    "        \n",
    "        self.hidden0 = nn.Sequential(\n",
    "            nn.Linear(n_features, 256),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.hidden1 = nn.Sequential(            \n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.hidden2 = nn.Sequential(\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(1024, n_out),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.type(torch.FloatTensor)\n",
    "        # print(\"Generator\", x.shape)\n",
    "        x = self.hidden0(x)\n",
    "        # print(x.shape)\n",
    "        x = self.hidden1(x)\n",
    "        # print(x.shape)\n",
    "        x = self.hidden2(x)\n",
    "        # print(x.shape)\n",
    "        x = self.out(x)\n",
    "        # print(x.shape)\n",
    "        return x\n",
    "    \n",
    "# Noise\n",
    "def noise(size):\n",
    "    n = Variable(torch.randn(size, 1000))\n",
    "    # n = Variable(torch.randn(size, 256))\n",
    "    if torch.cuda.is_available(): return n.cuda() \n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = DiscriminatorNet()\n",
    "generator = GeneratorNet()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    discriminator.cuda()\n",
    "    generator.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1            [-1, 904, 1024]       1,293,312\n",
      "         LeakyReLU-2            [-1, 904, 1024]               0\n",
      "           Dropout-3            [-1, 904, 1024]               0\n",
      "            Linear-4             [-1, 904, 512]         524,800\n",
      "         LeakyReLU-5             [-1, 904, 512]               0\n",
      "           Dropout-6             [-1, 904, 512]               0\n",
      "            Linear-7             [-1, 904, 256]         131,328\n",
      "         LeakyReLU-8             [-1, 904, 256]               0\n",
      "           Dropout-9             [-1, 904, 256]               0\n",
      "           Linear-10               [-1, 904, 1]             257\n",
      "          Sigmoid-11               [-1, 904, 1]               0\n",
      "================================================================\n",
      "Total params: 1,949,697\n",
      "Trainable params: 1,949,697\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 4.35\n",
      "Forward/backward pass size (MB): 37.09\n",
      "Params size (MB): 7.44\n",
      "Estimated Total Size (MB): 48.88\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(discriminator,input_size=(X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1             [-1, 904, 256]         256,256\n",
      "         LeakyReLU-2             [-1, 904, 256]               0\n",
      "            Linear-3             [-1, 904, 512]         131,584\n",
      "         LeakyReLU-4             [-1, 904, 512]               0\n",
      "            Linear-5            [-1, 904, 1024]         525,312\n",
      "         LeakyReLU-6            [-1, 904, 1024]               0\n",
      "            Linear-7            [-1, 904, 1262]       1,293,550\n",
      "              Tanh-8            [-1, 904, 1262]               0\n",
      "================================================================\n",
      "Total params: 2,206,702\n",
      "Trainable params: 2,206,702\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.45\n",
      "Forward/backward pass size (MB): 42.13\n",
      "Params size (MB): 8.42\n",
      "Estimated Total Size (MB): 53.99\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(generator,input_size=((X.shape[0], 1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer=SummaryWriter('./runs/logsdir')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=0.0002)\n",
    "\n",
    "# Loss function\n",
    "loss = nn.BCELoss()\n",
    "\n",
    "# Number of steps to apply to the discriminator\n",
    "d_steps = 1  # In Goodfellow et. al 2014 this variable is assigned to 1\n",
    "# Number of epochs\n",
    "num_epochs = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bleh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_data_target(size):\n",
    "    '''\n",
    "    Tensor containing ones, with shape = size\n",
    "    '''\n",
    "    data = Variable(torch.ones(size, 1))#.type(torch.LongTensor)\n",
    "    if torch.cuda.is_available(): return data.cuda()\n",
    "    return data\n",
    "\n",
    "def fake_data_target(size):\n",
    "    '''\n",
    "    Tensor containing zeros, with shape = size\n",
    "    '''\n",
    "    data = Variable(torch.zeros(size, 1))#.type(torch.LongTensor)\n",
    "    if torch.cuda.is_available(): return data.cuda()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(optimizer, real_data, fake_data):\n",
    "    # Reset gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 1.1 Train on Real Data\n",
    "    # print(\"Training Discriminator on real data\")\n",
    "    prediction_real = discriminator(real_data)\n",
    "    # Calculate error and backpropagate\n",
    "    # print(\"real_data:\", real_data.size(), \n",
    "    #     \"\\nprediction_real:\", prediction_real.size(),\n",
    "    #     \"\\nreal_data_target:\", real_data_target(real_data.size(0)).size())\n",
    "        \n",
    "    error_real = loss(prediction_real, real_data_target(real_data.size(0)))\n",
    "    error_real.backward()\n",
    "\n",
    "    # 1.2 Train on Fake Data\n",
    "    prediction_fake = discriminator(fake_data)\n",
    "    # Calculate error and backpropagate\n",
    "    error_fake = loss(prediction_fake, fake_data_target(real_data.size(0)))\n",
    "    error_fake.backward()\n",
    "    \n",
    "    # 1.3 Update weights with gradients\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Return error\n",
    "    return error_real + error_fake, prediction_real, prediction_fake\n",
    "\n",
    "def train_generator(optimizer, fake_data):\n",
    "    # 2. Train Generator\n",
    "    # Reset gradients\n",
    "    optimizer.zero_grad()\n",
    "    # Sample noise and generate fake data\n",
    "    prediction = discriminator(fake_data)\n",
    "    # Calculate error and backpropagate\n",
    "    error = loss(prediction, real_data_target(prediction.size(0)))\n",
    "    error.backward()\n",
    "    # Update weights with gradients\n",
    "    optimizer.step()\n",
    "    # Return error\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Samples for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1000])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_test_samples = 16\n",
    "test_noise = noise(num_test_samples)\n",
    "test_noise.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [70/200], Batch Num: [0/28]\n",
      "Discriminator Loss: 0.3743, Generator Loss: 2.1095\n",
      "D(x): 0.8693, D(G(z)): 0.1744\n"
     ]
    }
   ],
   "source": [
    "logging = Logger(model_name='VGAN', data_name='tcc_ceds_music_dataset')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # for n_batch, real_batch in tqdm(enumerate(dataloader)):\n",
    "    for n_batch, real_batch in enumerate(dataloader):\n",
    "        # print(n_batch, real_batch.size())\n",
    "\n",
    "        # 1. Train Discriminator\n",
    "        real_data = Variable(real_batch)\n",
    "        if torch.cuda.is_available(): real_data = real_data.cuda()\n",
    "        \n",
    "        # Generate fake data and train G\n",
    "        \n",
    "        # print(real_data.size(), real_data.size(0), noise(real_data.size(0)).size())\n",
    "        fake_data = generator(noise(real_data.size(0))).detach()\n",
    "        # print(\"Fake Data:\",fake_data.shape)\n",
    "        \n",
    "        # Train D\n",
    "        d_error, d_pred_real, d_pred_fake = train_discriminator(d_optimizer,\n",
    "                                                                real_data, fake_data)\n",
    "\n",
    "        # 2. Train Generator\n",
    "        # Generate fake data\n",
    "        fake_data = generator(noise(real_batch.size(0)))\n",
    "        # Train G\n",
    "        g_error = train_generator(g_optimizer, fake_data)\n",
    "        # Log error\n",
    "        logging.log(d_error, g_error, epoch, n_batch, num_batches)\n",
    "\n",
    "        # Display Progress\n",
    "        if (n_batch) % 50 == 0:\n",
    "            display.clear_output(True)\n",
    "            # Display Images\n",
    "            test_output = generator(test_noise).data.cpu().type(torch.FloatTensor)\n",
    "            test_text = vec_to_text(test_output)\n",
    "            # logging.log_images(test_text, num_test_samples, epoch, n_batch, num_batches)\n",
    "            # Display status Logs\n",
    "            logging.display_status(\n",
    "                epoch, num_epochs, n_batch, num_batches,\n",
    "                d_error, g_error, d_pred_real, d_pred_fake\n",
    "            )\n",
    "        #Model Checkpoints\n",
    "        logging.save_models(generator, discriminator, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['away baby believe better cause close come dear dream eye fall good hand head hear leave life line live look mind need open people play sing sleep song start stay tell think touch true want wish write',\n",
       " 'blue days gonna hear kiss know life live need stay tell think want',\n",
       " 'baby better blue break breathe bring cause change come dream easy fall fight get girl give gonna hear know leave like live lose need pain pretty real save sleep song soon sorrow start stay summer talk tell today tomorrow turn want watch word world',\n",
       " 'ahead arm away better blood blow blue break bring burn change club come dance days dream fear follow forget fuck future get girl go gonna hang kiss know leave lie life like little lonely long lose love make meet mind money mother need night ohoh pity point return sail say scream secret shoot sleep somebody soon start stay street string time tonight tree try turn walk want watch whisper wind woman world',\n",
       " 'arm away beauty better blood break breathe bring burn cause change come cover days fight follow get girl go gonna hear heart hurt know leave lie live lonely long lose love need night pain rain remember say scream sleep somebody soon sound start stay talk till time try voice walk want wind',\n",
       " 'ahead arm away better black blood blue break breathe bring build bury change come cry days deep desire devil drop fear fight follow forget fuck get girl go gonna grind grow hear help house hurt kill leave lie light live lonely long lose money need night ohoh oooh open pain party pity pretty rain ready sense sleep somebody song sound stand stay take talk till time true try turn want wind yeah',\n",
       " 'away blue breathe change gonna hear leave live look lose need pain play rain stay time want',\n",
       " 'ahead arm away better black blue break bring burn change come cover days desire fear fight follow girl go gonna hear help hold hurt kill know leave lonely long lose love make need night pain place rain return shame shoot somebody soon stay time try walk want watch whisper',\n",
       " 'baby change come dream fall hand know leave life live look lose need sleep start stay tell want',\n",
       " 'better blue break change come cover days fight girl gonna hear know leave live lonely lose love need pain rain remember sleep start stay time want',\n",
       " 'arm change come dream eye forget girl go hard heart hold kiss know leave life live lonely lose mind need rain remember say soul tell time',\n",
       " 'arm away black blue bring days gonna hear leave live rain ready sleep song stay time want',\n",
       " 'away baby better blue break breathe change come days dream fear fight get give go gonna hard help hurt kiss know leave live lose need pain pretty real start stay strong summer tear time walk want',\n",
       " 'ahead arm better black blue break bring change come cover days fight follow girl gonna hear kill leave light live lonely lose need pain place rain ready remember sleep stay talk try want',\n",
       " 'arm away blue dream feel gonna good hear leave life look people rain stay take think want yeah',\n",
       " 'away baby better change days dream girl gonna know leave life live lonely look lose need sleep stay turn want']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_to_text(generator(test_noise).data.cpu().type(torch.FloatTensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# END\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
